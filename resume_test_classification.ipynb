{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Category                                             Resume\n",
       "0   1       HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1   2       HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2   3       HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3   4       HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4   5       HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./resume_dataset_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove pucntuation in Resume\n",
    "import string\n",
    "new_resume_list = []\n",
    "for resume in df['Resume']:\n",
    "    new_r = resume.translate(str.maketrans('', '', string.punctuation))\n",
    "    new_resume_list.append(new_r)\n",
    "\n",
    "new_resume = np.asarray(new_resume_list)\n",
    "df['Normalized_Resume'] = new_resume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import textract\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def pdf2txt(file_path: str) -> str:\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "        texts = ''\n",
    "        np = pdf_reader.getNumPages()\n",
    "        for i in range(np):\n",
    "            texts += pdf_reader.getPage(i).extractText()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    SVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 9626)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Term Frequency, Inverse Document Frequency\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf = True, min_df =7, norm = 'l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.Normalized_Resume).toarray()\n",
    "labels = df.ID\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Accountant':\n",
      "  . Most correlated unigrams:\n",
      ". equal\n",
      ". faced\n",
      "  . Most correlated bigrams:\n",
      ". account executive\n",
      ". various clients\n",
      "# 'Advocate':\n",
      "  . Most correlated unigrams:\n",
      ". protect\n",
      ". doctoral\n",
      "  . Most correlated bigrams:\n",
      ". law university\n",
      ". public law\n",
      "# 'Agricultural':\n",
      "  . Most correlated unigrams:\n",
      ". animal\n",
      ". feed\n",
      "  . Most correlated bigrams:\n",
      ". xe2x80x93 2005\n",
      ". experience job\n",
      "# 'Apparel':\n",
      "  . Most correlated unigrams:\n",
      ". fabric\n",
      ". fame\n",
      "  . Most correlated bigrams:\n",
      ". promotional materials\n",
      ". institute art\n",
      "# 'Architects':\n",
      "  . Most correlated unigrams:\n",
      ". contains\n",
      ". schematic\n",
      "  . Most correlated bigrams:\n",
      ". year experience\n",
      ". mechanical electrical\n",
      "# 'Arts':\n",
      "  . Most correlated unigrams:\n",
      ". paint\n",
      ". blend\n",
      "  . Most correlated bigrams:\n",
      ". fulltime position\n",
      ". commonly used\n",
      "# 'Automobile':\n",
      "  . Most correlated unigrams:\n",
      ". damaged\n",
      ". repaired\n",
      "  . Most correlated bigrams:\n",
      ". institute technology\n",
      ". xe2x80x93 2004\n",
      "# 'Aviation':\n",
      "  . Most correlated unigrams:\n",
      ". documentary\n",
      ". depaul\n",
      "  . Most correlated bigrams:\n",
      ". il august\n",
      ". combination resume\n",
      "# 'BPO':\n",
      "  . Most correlated unigrams:\n",
      ". alongnwith\n",
      ". array\n",
      "  . Most correlated bigrams:\n",
      ". sound knowledge\n",
      ". end end\n",
      "# 'Banking':\n",
      "  . Most correlated unigrams:\n",
      ". numbernemail\n",
      ". specify\n",
      "  . Most correlated bigrams:\n",
      ". experience skills\n",
      ". personal details\n",
      "# 'Building & Construction':\n",
      "  . Most correlated unigrams:\n",
      ". new\n",
      ". xe2x80x93\n",
      "  . Most correlated bigrams:\n",
      ". new york\n",
      ". customer service\n",
      "# 'Business Development':\n",
      "  . Most correlated unigrams:\n",
      ". practicum\n",
      ". supervisorxe2x80x99s\n",
      "  . Most correlated bigrams:\n",
      ". ability learn\n",
      ". strong relationships\n",
      "# 'Consultant':\n",
      "  . Most correlated unigrams:\n",
      ". korea\n",
      ". seoul\n",
      "  . Most correlated bigrams:\n",
      ". market opportunities\n",
      ". relevant courses\n",
      "# 'Designing':\n",
      "  . Most correlated unigrams:\n",
      ". keyword\n",
      ". hat\n",
      "  . Most correlated bigrams:\n",
      ". engine optimization\n",
      ". red hat\n",
      "# 'Digital Media':\n",
      "  . Most correlated unigrams:\n",
      ". yearnxefx82xb7\n",
      ". depaul\n",
      "  . Most correlated bigrams:\n",
      ". ilnbachelor science\n",
      ". career advising\n",
      "# 'Education':\n",
      "  . Most correlated unigrams:\n",
      ". populations\n",
      ". dell\n",
      "  . Most correlated bigrams:\n",
      ". services university\n",
      ". year xe2x80x93\n",
      "# 'Engineering':\n",
      "  . Most correlated unigrams:\n",
      ". capstone\n",
      ". sometown\n",
      "  . Most correlated bigrams:\n",
      ". software engineering\n",
      ". requirements developed\n",
      "# 'Finance':\n",
      "  . Most correlated unigrams:\n",
      ". ventures\n",
      ". pension\n",
      "  . Most correlated bigrams:\n",
      ". chicago ilnmaster\n",
      ". corporate finance\n",
      "# 'Food & Beverages':\n",
      "  . Most correlated unigrams:\n",
      ". stars\n",
      ". hotels\n",
      "  . Most correlated bigrams:\n",
      ". food beverage\n",
      ". award best\n",
      "# 'HR':\n",
      "  . Most correlated unigrams:\n",
      ". containment\n",
      ". callahan\n",
      "  . Most correlated bigrams:\n",
      ". processing accounts\n",
      ". creative problem\n",
      "# 'Health & Fitness':\n",
      "  . Most correlated unigrams:\n",
      ". radiology\n",
      ". positioned\n",
      "  . Most correlated bigrams:\n",
      ". maintaining high\n",
      ". memorial hospital\n",
      "# 'Information Technology':\n",
      "  . Most correlated unigrams:\n",
      ". xe2x80x9cto\n",
      ". molecular\n",
      "  . Most correlated bigrams:\n",
      ". new york\n",
      ". et al\n",
      "# 'Managment':\n",
      "  . Most correlated unigrams:\n",
      ". guildsnnpersonal\n",
      ". extensivenexperience\n",
      "  . Most correlated bigrams:\n",
      ". marketing manager\n",
      ". team implement\n",
      "# 'Public Relations':\n",
      "  . Most correlated unigrams:\n",
      ". commendation\n",
      ". dakota\n",
      "  . Most correlated bigrams:\n",
      ". including word\n",
      ". customer retention\n",
      "# 'Sales':\n",
      "  . Most correlated unigrams:\n",
      ". lifting\n",
      ". queriesnxefx82xb7\n",
      "  . Most correlated bigrams:\n",
      ". giving presentations\n",
      ". monthly reportsnxefx82xb7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "N = 2\n",
    "category_id_df = df[['Category','ID']].drop_duplicates().sort_values('ID')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "for Category, ID in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == ID)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}':\".format(Category))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Resume'], df['Category'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Engineering', 'Engineering', 'Education', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Education', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Education', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Education', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Education', 'Engineering',\n",
       "       'Education', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Information Technology', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Information Technology',\n",
       "       'Engineering', 'Managment', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Education', 'Engineering',\n",
       "       'Engineering', 'Information Technology', 'Information Technology',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Education', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Managment',\n",
       "       'Information Technology', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Education', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Education', 'Education', 'Education',\n",
       "       'Engineering', 'Engineering', 'Education', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Information Technology',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Managment',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Information Technology', 'Managment', 'Education',\n",
       "       'Engineering', 'Education', 'Engineering', 'Sales', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Managment', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Education', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Education', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Engineering', 'Advocate',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Information Technology',\n",
       "       'Education', 'Engineering', 'Engineering', 'Sales', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Managment', 'Engineering', 'Education', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Education', 'Engineering', 'Engineering',\n",
       "       'Information Technology', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Education', 'Engineering', 'Education', 'Information Technology',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Managment', 'Engineering', 'Engineering', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering', 'Engineering',\n",
       "       'Education', 'Engineering', 'Managment', 'Engineering',\n",
       "       'Engineering', 'Engineering', 'Information Technology',\n",
       "       'Engineering', 'Information Technology', 'Education',\n",
       "       'Engineering', 'Engineering', 'Engineering'], dtype='<U23')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(count_vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
